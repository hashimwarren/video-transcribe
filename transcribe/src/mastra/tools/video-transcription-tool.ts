import { createTool } from '@mastra/core/tools';
import { z } from 'zod';
import { promises as fs } from 'node:fs';
import { createWriteStream } from 'node:fs';
import { tmpdir } from 'node:os';
import { basename, join } from 'node:path';
import { randomUUID } from 'node:crypto';
import { pipeline } from 'node:stream/promises';
import { Readable } from 'node:stream';

const urlSourceSchema = z.object({
  sourceType: z.literal('url'),
  url: z.string().url().describe('Publicly accessible URL to the video file.'),
  filename: z
    .string()
    .optional()
    .describe('Optional filename to use when downloading the video.'),
});

const fileSourceSchema = z.object({
  sourceType: z.literal('file'),
  path: z.string().describe('Absolute path to a video file accessible to the server.'),
});

export const videoSourceSchema = z.discriminatedUnion('sourceType', [urlSourceSchema, fileSourceSchema]);

export const videoTranscriptionInputSchema = z
  .object({
    prompt: z
      .string()
      .optional()
      .describe('Optional hints (names, terminology) that help the transcription model.'),
  })
  .and(videoSourceSchema);

export const videoTranscriptionOutputSchema = z.object({
  transcript: z.string().describe('Full transcript generated by the model.'),
  durationSeconds: z
    .number()
    .nullable()
    .describe('Duration of the audio track when provided by the transcription model.'),
  model: z.string().describe('Model identifier used to create the transcript.'),
  source: z.string().describe('Original video source (URL or file path).'),
});

export type VideoTranscriptionInput = z.infer<typeof videoTranscriptionInputSchema>;

export const videoTranscriptionTool = createTool({
  id: 'video-transcription',
  description: 'Transcribe speech from a video file using OpenAI\'s Whisper (gpt-4o-mini-transcribe).',
  inputSchema: videoTranscriptionInputSchema,
  outputSchema: videoTranscriptionOutputSchema,
  execute: async ({ context }) => {
    return transcribeVideoWithOpenAI(context);
  },
});

export async function transcribeVideoWithOpenAI(input: VideoTranscriptionInput) {
  const { prompt, ...source } = input;
  const resolved = await resolveVideoSource(source);

  try {
    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
      throw new Error('OPENAI_API_KEY environment variable is required to transcribe videos.');
    }

    const fileBuffer = await fs.readFile(resolved.path);
    const fileName = deriveFileName(resolved.original);
    const form = new FormData();
    form.append('model', 'gpt-4o-mini-transcribe');
    form.append('response_format', 'json');
    if (prompt) {
      form.append('prompt', prompt);
    }
    form.append('file', new Blob([fileBuffer]), fileName);

    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${apiKey}`,
      },
      body: form,
    });

    if (!response.ok) {
      const errorText = await response.text();
      throw new Error(`OpenAI transcription failed (${response.status}): ${errorText}`);
    }

    const transcription = (await response.json()) as {
      text?: string;
      duration?: number | string;
      model?: string;
    };

    return {
      transcript: transcription.text ?? '',
      durationSeconds: typeof transcription.duration === 'number'
        ? transcription.duration
        : transcription.duration
          ? Number.parseFloat(String(transcription.duration)) || null
          : null,
      model: transcription.model ?? 'gpt-4o-mini-transcribe',
      source: resolved.original,
    };
  } finally {
    await resolved.cleanup?.();
  }
}

type ResolvedVideoSource = {
  path: string;
  cleanup?: () => Promise<void>;
  original: string;
};

type VideoSource = z.infer<typeof videoSourceSchema>;

async function resolveVideoSource(source: VideoSource): Promise<ResolvedVideoSource> {
  if (source.sourceType === 'file') {
    await ensureFileExists(source.path);
    return {
      path: source.path,
      original: source.path,
    };
  }

  const { tempFilePath, cleanup } = await downloadVideo(source.url, source.filename);

  return {
    path: tempFilePath,
    cleanup,
    original: source.url,
  };
}

async function ensureFileExists(path: string) {
  const stats = await fs.stat(path).catch(() => {
    throw new Error(`Video file not found at path: ${path}`);
  });

  if (!stats.isFile()) {
    throw new Error(`Provided path is not a file: ${path}`);
  }
}

async function downloadVideo(url: string, filename?: string) {
  const response = await fetch(url);

  if (!response.ok) {
    throw new Error(`Failed to download video. Received ${response.status} ${response.statusText}`);
  }

  if (!response.body) {
    throw new Error('The response body was empty while attempting to download the video.');
  }

  const tempDir = await fs.mkdtemp(join(tmpdir(), 'mastra-transcribe-'));
  const derivedName = filename ?? deriveFileName(url);
  const tempFilePath = join(tempDir, derivedName);
  const writable = createWriteStream(tempFilePath);
  const readable = response.body instanceof Readable ? response.body : Readable.fromWeb(response.body as any);

  await pipeline(readable, writable);

  const cleanup = async () => {
    await fs.rm(tempDir, { recursive: true, force: true });
  };

  return { tempFilePath, cleanup };
}

function deriveFileName(source: string) {
  try {
    if (source.startsWith('http')) {
      const parsed = new URL(source);
      const pathname = parsed.pathname;
      const name = basename(pathname);
      if (name) {
        return name;
      }
    } else {
      const name = basename(source);
      if (name) {
        return name;
      }
    }
  } catch (error) {
    // Ignore parsing errors and fall back to a random filename
  }

  return `video-${randomUUID()}`;
}
